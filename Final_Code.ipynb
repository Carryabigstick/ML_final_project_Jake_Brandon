{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce3e4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main import block \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "from sklearn.calibration import Parallel, delayed\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c81cf046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data loaded successfully.\n",
      "Training data shape: (3644, 8)\n",
      "Testing data shape: (3084, 8)\n",
      "\n",
      "Original shape: (3644, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import data and show shapes\n",
    "try:\n",
    "    train_df = pd.read_csv('train_motion_data.csv')\n",
    "    test_df = pd.read_csv('test_motion_data.csv')\n",
    "    print(\"Train and test data loaded successfully.\")\n",
    "    print(f\"Training data shape: {train_df.shape}\")\n",
    "    print(f\"Testing data shape: {test_df.shape}\\n\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'train_motion_data.csv' and 'test_motion_data.csv' are in the same directory.\")\n",
    "    exit()\n",
    "\n",
    "train_df\n",
    "\n",
    "print(f\"Original shape: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc81b917",
   "metadata": {},
   "source": [
    "As we can see, our training and testing data is of a similar size which will be useful when predicting our models and measuring accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8ce5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "features = ['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ']\n",
    "target = 'Class'\n",
    "\n",
    "# Get train and test subsets \n",
    "X_train = train_df[features]\n",
    "y_train_labels = train_df[target]\n",
    "X_test = test_df[features]\n",
    "y_test_labels = test_df[target]\n",
    "\n",
    "# Encode labels into numbers that can be processed by various ML models.\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_labels)\n",
    "y_test = le.transform(y_test_labels)\n",
    "\n",
    "# scale X training data only to ensure data is within similar values \n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fb865",
   "metadata": {},
   "source": [
    "Now All of our data is scaled, encoded and ready to use! Time to start testing different models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31131a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y_train_labels, order=le.classes_)\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.xlabel('Driving Style')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6533c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a96b3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create result grid to store classification results \n",
    "results = {}\n",
    "\n",
    "\n",
    "def run_grid_search(model, param_grid, X_train, y_train, X_test, y_test):\n",
    "\n",
    "\n",
    "    \n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    print(f\"Testing {len(param_combinations)} candidate models...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Trains a single model and evaluates it on the test set.\n",
    "    def evaluate_candidate(params, X_train, y_train, X_test, y_test):\n",
    "        # model = RandomForestClassifier(random_state=42, n_jobs=1, **params)\n",
    "\n",
    "        candidate_model = clone(model)\n",
    "        candidate_model.set_params(**params)\n",
    "        \n",
    "        # Train\n",
    "        candidate_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        predictions = candidate_model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        # Return dictionary of results\n",
    "        result = params.copy()\n",
    "        result['test_accuracy'] = acc\n",
    "        return result\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    results = Parallel(n_jobs=-1, verbose=1)(\n",
    "    delayed(evaluate_candidate)(params, X_train, y_train, X_test, y_test)\n",
    "    for params in param_combinations\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nGrid Search completed in {end_time - start_time:.2f} seconds.\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Sort by Test Accuracy (Descending)\n",
    "    best_model = results_df.sort_values(by='test_accuracy', ascending=False).iloc[0]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"       WINNING MODEL FOUND\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Best Test Accuracy: {best_model['test_accuracy']:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    for key, value in best_model.items():\n",
    "        if key == 'test_accuracy':\n",
    "            continue\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    best_params = best_model.drop('test_accuracy').to_dict()\n",
    "\n",
    "    best_params = {\n",
    "    k: int(v) if isinstance(v, float) and v.is_integer() else v \n",
    "    for k, v in best_params.items()\n",
    "    }\n",
    "    \n",
    "    # 2. Create a fresh model with the winning settings\n",
    "    final_model = clone(model)\n",
    "    final_model.set_params(**best_params)\n",
    "    \n",
    "    # 3. Retrain on the full training set\n",
    "    final_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 4. Predict and Report\n",
    "    final_predictions = final_model.predict(X_test)\n",
    "\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"                     CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    report_str = classification_report(y_test, final_predictions)\n",
    "    report_dict = classification_report(y_test, final_predictions, output_dict=True)\n",
    "    print(report_str)\n",
    "\n",
    "    return model_name, report_dict \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f33a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON GRAIDENT BOOSTING CLASSIFIER MODEL\n",
      "Testing 32 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 3.09 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.4724\n",
      "----------------------------------------\n",
      "n_estimators: 100\n",
      "learning_rate: 0.01\n",
      "max_depth: 4\n",
      "subsample: 0.7\n",
      "min_samples_split: 10\n",
      "min_samples_leaf: 4\n",
      "max_features: sqrt\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.35      0.41       814\n",
      "           1       0.32      0.05      0.09       997\n",
      "           2       0.47      0.86      0.61      1273\n",
      "\n",
      "    accuracy                           0.46      3084\n",
      "   macro avg       0.42      0.42      0.37      3084\n",
      "weighted avg       0.43      0.46      0.39      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Graident Boosting Classifier Test: \n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of boosting stages (trees)\n",
    "    'learning_rate': [0.01, 0.2],  # Step size shrinkage to prevent overfitting\n",
    "    'max_depth': [3, 4],  # Maximum depth of the individual regression estimators\n",
    "    'subsample': [0.7],  # Fraction of samples used for fitting the individual base learners\n",
    "    'min_samples_split': [2, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt']  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON GRAIDENT BOOSTING CLASSIFIER MODEL\")\n",
    "name, report = run_grid_search(gb_model,param_grid,X_train,y_train,X_test,y_test)\n",
    "\n",
    "results[name] = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efc3fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON BAGGING CLASSIFER MODEL\n",
      "Testing 54 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 3.11 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.4248\n",
      "----------------------------------------\n",
      "n_estimators: 100\n",
      "max_samples: 1.0\n",
      "max_features: 1.0\n",
      "bootstrap_features: True\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       814\n",
      "           1       0.32      1.00      0.49       997\n",
      "           2       0.00      0.00      0.00      1273\n",
      "\n",
      "    accuracy                           0.32      3084\n",
      "   macro avg       0.11      0.33      0.16      3084\n",
      "weighted avg       0.10      0.32      0.16      3084\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Bagging Classifier Test: \n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.75, 1.0],\n",
    "    'max_features': [0.5, 0.75, 1.0],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON BAGGING CLASSIFER MODEL\")\n",
    "name, report = run_grid_search(bag_model,param_grid,X_train,y_train,X_test,y_test)\n",
    "\n",
    "results[name] = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45d34c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON HIST GRAIDENT BOOSTING CLASSIFIER MODEL\n",
      "Testing 432 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed:   41.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 41.32 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.4582\n",
      "----------------------------------------\n",
      "learning_rate: 0.01\n",
      "max_leaf_nodes: 20.0\n",
      "max_iter: 100.0\n",
      "l2_regularization: 0.0\n",
      "max_bins: 255.0\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.41      0.44       814\n",
      "           1       0.35      0.17      0.23       997\n",
      "           2       0.48      0.71      0.58      1273\n",
      "\n",
      "    accuracy                           0.46      3084\n",
      "   macro avg       0.43      0.43      0.41      3084\n",
      "weighted avg       0.44      0.46      0.43      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hist Graident Boosting Classifier Test: \n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "hgb_model = HistGradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_leaf_nodes': [20, 31, 50, 100],\n",
    "    'max_iter': [100, 200, 500],\n",
    "    'l2_regularization': [0.0, 0.1, 1.0],\n",
    "    'max_bins': [63, 127, 255]\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON HIST GRAIDENT BOOSTING CLASSIFIER MODEL\")\n",
    "name, report = run_grid_search(hgb_model,param_grid,X_train,y_train,X_test,y_test)\n",
    "results[name] = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON HIST GRAIDENT BOOSTING CLASSIFIER MODEL\n",
      "Testing 96 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.1s\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jcshavel/anaconda3/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:   20.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 20.16 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.4608\n",
      "----------------------------------------\n",
      "hidden_layer_sizes: (100,)\n",
      "activation: tanh\n",
      "solver: sgd\n",
      "alpha: 0.05\n",
      "learning_rate_init: 0.001\n",
      "max_iter: 200\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.27      0.34       814\n",
      "           1       0.36      0.11      0.17       997\n",
      "           2       0.46      0.85      0.60      1273\n",
      "\n",
      "    accuracy                           0.45      3084\n",
      "   macro avg       0.44      0.41      0.37      3084\n",
      "weighted avg       0.43      0.45      0.39      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_model = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100), (150, 100, 50)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'max_iter': [200, 300]\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON HIST GRAIDENT BOOSTING CLASSIFIER MODEL\")\n",
    "name, report = run_grid_search(mlp_model,param_grid,X_train,y_train,X_test,y_test)\n",
    "results[name] = report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2e49f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON ADA BOOST CLASSIFIER MODEL\n",
      "Testing 15 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 0.54 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.4640\n",
      "----------------------------------------\n",
      "n_estimators: 100.0\n",
      "learning_rate: 1.0\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.42       814\n",
      "           1       0.30      0.02      0.03       997\n",
      "           2       0.47      0.86      0.61      1273\n",
      "\n",
      "    accuracy                           0.46      3084\n",
      "   macro avg       0.41      0.42      0.35      3084\n",
      "weighted avg       0.41      0.46      0.37      3084\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON ADA BOOST CLASSIFIER MODEL\")\n",
    "name, report = run_grid_search(ada_model,param_grid,X_train,y_train,X_test,y_test)\n",
    "results[name] = report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c567bb1",
   "metadata": {},
   "source": [
    "As we can see, our accuracy hovers around 40%, with f1 scores and precision that is not much better. Why is this? Well, it is seemingly quite difficult to not overfit our data and at the same time get good idea of the trend of the testing data. To combat this we can try a sliding window technique. We will loop through our dataset, looking at values from n to n+window_size. For each of these rows inside the window, we will calculate mean, standard deviation, min and max for each feature. This will allow us to see more trends and hopefully create a more accurate model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "debaa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 150\n",
    "\n",
    "def create_time_series_features(df, feature_cols, window_size):\n",
    "    \"\"\"\n",
    "    Creates time-series features based on a rolling window.\n",
    "    \"\"\"\n",
    "    df_sorted = df.sort_values(by=timestamp_col).copy()\n",
    "\n",
    "    df_out = df_sorted[[timestamp_col, target_col]].copy()\n",
    "\n",
    "    for col in feature_cols:\n",
    "        # .rolling() creates the window object.\n",
    "        # We then apply aggregate functions like .mean(), .std(), etc.\n",
    "        df_out[f'{col}_mean_{window_size}'] = df_sorted[col].rolling(window=window_size).mean()\n",
    "        df_out[f'{col}_std_{window_size}'] = df_sorted[col].rolling(window=window_size).std()\n",
    "        df_out[f'{col}_max_{window_size}'] = df_sorted[col].rolling(window=window_size).max()\n",
    "        df_out[f'{col}_min_{window_size}'] = df_sorted[col].rolling(window=window_size).min()\n",
    "\n",
    "    df_out = df_out.dropna()\n",
    "\n",
    "    return df_out\n",
    "\n",
    "feature_cols = ['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ']\n",
    "target_col = 'Class'\n",
    "timestamp_col = 'Timestamp'\n",
    "\n",
    "df_train_engineered = create_time_series_features(train_df, feature_cols, WINDOW_SIZE)\n",
    "df_test_engineered = create_time_series_features(test_df,feature_cols, WINDOW_SIZE)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "features = df_train_engineered.columns.to_list();\n",
    "features.remove('Class')\n",
    "target = 'Class'\n",
    "\n",
    "# Get train and test subsets \n",
    "X_train = df_train_engineered[features]\n",
    "y_train_labels = df_train_engineered[target]\n",
    "X_test = df_test_engineered[features]\n",
    "y_test_labels = df_test_engineered[target]\n",
    "\n",
    "# Encode labels into numbers that can be processed by various ML models.\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_labels)\n",
    "y_test = le.transform(y_test_labels)\n",
    "\n",
    "# scale X training data only to ensure data is within similar values \n",
    "scaler = StandardScaler()\n",
    "X_train_eng = scaler.fit_transform(X_train)\n",
    "X_test_eng = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc018ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON RANDOM FOREST CLASSIFIER MODEL\n",
      "Testing 320 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 18.58 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.7019\n",
      "----------------------------------------\n",
      "n_estimators: 710\n",
      "max_depth: 4\n",
      "min_samples_leaf: 734\n",
      "min_samples_split: 2.0\n",
      "criterion: gini\n",
      "max_features: sqrt\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.97      0.76       665\n",
      "           1       0.69      0.50      0.58       997\n",
      "           2       0.77      0.72      0.75      1273\n",
      "\n",
      "    accuracy                           0.70      2935\n",
      "   macro avg       0.70      0.73      0.70      2935\n",
      "weighted avg       0.71      0.70      0.69      2935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try random forest with new 'eng' engineered values \n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)  \n",
    "\n",
    "rf_param_grid_regularized = {\n",
    "    'n_estimators': [710,723,720,700,709],\n",
    "    'max_depth': [1,2,4,8],\n",
    "    'min_samples_leaf': [730,734,736,700],\n",
    "    'min_samples_split': [0.1,0.5,1.0,2],\n",
    "    'criterion': ['gini'],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON RANDOM FOREST CLASSIFIER MODEL\")\n",
    "name, report = run_grid_search(rf_model,rf_param_grid_regularized,X_train_eng,y_train,X_test_eng,y_test)\n",
    "results[name + '_eng'] = report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8c3f5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 648 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m gb_model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],  \u001b[38;5;66;03m# Number of boosting stages (trees)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m],  \u001b[38;5;66;03m# Step size shrinkage to prevent overfitting\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]  \u001b[38;5;66;03m# Number of features to consider when looking for the best split\u001b[39;00m\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m name, report \u001b[38;5;241m=\u001b[39m run_grid_search(gb_model,param_grid,X_train_eng,y_train,X_test_eng,y_test)\n\u001b[1;32m     15\u001b[0m results[name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eng\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m report\n",
      "Cell \u001b[0;32mIn[72], line 37\u001b[0m, in \u001b[0;36mrun_grid_search\u001b[0;34m(model, param_grid, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     34\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 37\u001b[0m results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)(\n\u001b[1;32m     38\u001b[0m delayed(evaluate_candidate)(params, X_train, y_train, X_test, y_test)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_combinations\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGrid Search completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.13/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# rerun gradient boosting model to see if we get better results\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of boosting stages (trees)\n",
    "    'learning_rate': [0.1, 0.2],  # Step size shrinkage to prevent overfitting\n",
    "    'max_depth': [3, 4],  # Maximum depth of the individual regression estimators\n",
    "    'subsample': [0.7, 0.8, 1.0],  # Fraction of samples used for fitting the individual base learners\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "name, report = run_grid_search(gb_model,param_grid,X_train_eng,y_train,X_test_eng,y_test)\n",
    "results[name + '_eng'] = report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6d9851b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING GRID SEARCH ON BAGGING CLASSIFER MODEL\n",
      "Testing 72 candidate models...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search completed in 1.68 seconds.\n",
      "\n",
      "========================================\n",
      "       WINNING MODEL FOUND\n",
      "========================================\n",
      "Best Test Accuracy: 0.6279\n",
      "----------------------------------------\n",
      "n_estimators: 50\n",
      "max_samples: 0.5\n",
      "max_features: 0.5\n",
      "bootstrap_features: True\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "                     CLASSIFICATION REPORT\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70       665\n",
      "           1       0.38      0.94      0.54       997\n",
      "           2       0.94      0.03      0.05      1273\n",
      "\n",
      "    accuracy                           0.46      2935\n",
      "   macro avg       0.73      0.52      0.43      2935\n",
      "weighted avg       0.73      0.46      0.36      2935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rerun bagging to see if we get better results\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_model = BaggingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_samples': [0.5, 0.75, 1.0,50],\n",
    "    'max_features': [0.5, 0.75, 1.0],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "print(\"RUNNING GRID SEARCH ON BAGGING CLASSIFER MODEL\")\n",
    "name, report = run_grid_search(bag_model,param_grid,X_train_eng,y_train,X_test_eng,y_test)\n",
    "results[name + '_eng'] = report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a2e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GradientBoostingClassifier': {'0': {'precision': 0.4806070826306914,\n",
       "   'recall': 0.3501228501228501,\n",
       "   'f1-score': 0.4051172707889126,\n",
       "   'support': 814.0},\n",
       "  '1': {'precision': 0.32335329341317365,\n",
       "   'recall': 0.05416248746238716,\n",
       "   'f1-score': 0.09278350515463918,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.47074010327022375,\n",
       "   'recall': 0.8593872741555381,\n",
       "   'f1-score': 0.608284681679177,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.4646562905317769,\n",
       "  'macro avg': {'precision': 0.4249001597713629,\n",
       "   'recall': 0.4212242039135918,\n",
       "   'f1-score': 0.36872848587424295,\n",
       "   'support': 3084.0},\n",
       "  'weighted avg': {'precision': 0.42569700073194283,\n",
       "   'recall': 0.4646562905317769,\n",
       "   'f1-score': 0.3880081105184639,\n",
       "   'support': 3084.0}},\n",
       " 'BaggingClassifier': {'0': {'precision': 0.0,\n",
       "   'recall': 0.0,\n",
       "   'f1-score': 0.0,\n",
       "   'support': 814.0},\n",
       "  '1': {'precision': 0.3232814526588846,\n",
       "   'recall': 1.0,\n",
       "   'f1-score': 0.4886057338887528,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1273.0},\n",
       "  'accuracy': 0.3232814526588846,\n",
       "  'macro avg': {'precision': 0.1077604842196282,\n",
       "   'recall': 0.3333333333333333,\n",
       "   'f1-score': 0.1628685779629176,\n",
       "   'support': 3084.0},\n",
       "  'weighted avg': {'precision': 0.10451089763323863,\n",
       "   'recall': 0.3232814526588846,\n",
       "   'f1-score': 0.15795717142901639,\n",
       "   'support': 3084.0}},\n",
       " 'MLPClassifier': {'0': {'precision': 0.4897959183673469,\n",
       "   'recall': 0.26535626535626533,\n",
       "   'f1-score': 0.34422310756972113,\n",
       "   'support': 814.0},\n",
       "  '1': {'precision': 0.3564356435643564,\n",
       "   'recall': 0.10832497492477432,\n",
       "   'f1-score': 0.16615384615384615,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.46025641025641023,\n",
       "   'recall': 0.8460329929300864,\n",
       "   'f1-score': 0.596180459451979,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.45428015564202334,\n",
       "  'macro avg': {'precision': 0.4354959907293712,\n",
       "   'recall': 0.40657141107037537,\n",
       "   'f1-score': 0.36885247105851543,\n",
       "   'support': 3084.0},\n",
       "  'weighted avg': {'precision': 0.4344898263427672,\n",
       "   'recall': 0.45428015564202334,\n",
       "   'f1-score': 0.3906584692151449,\n",
       "   'support': 3084.0}},\n",
       " 'AdaBoostClassifier': {'0': {'precision': 0.45021037868162694,\n",
       "   'recall': 0.39434889434889436,\n",
       "   'f1-score': 0.4204322200392927,\n",
       "   'support': 814.0},\n",
       "  '1': {'precision': 0.2982456140350877,\n",
       "   'recall': 0.017051153460381142,\n",
       "   'f1-score': 0.03225806451612903,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.47234226447709593,\n",
       "   'recall': 0.8586017282010998,\n",
       "   'f1-score': 0.6094229160858656,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.46400778210116733,\n",
       "  'macro avg': {'precision': 0.40693275239793686,\n",
       "   'recall': 0.42333392533679176,\n",
       "   'f1-score': 0.3540377335470957,\n",
       "   'support': 3084.0},\n",
       "  'weighted avg': {'precision': 0.4102184916080317,\n",
       "   'recall': 0.46400778210116733,\n",
       "   'f1-score': 0.3729534661517094,\n",
       "   'support': 3084.0}},\n",
       " 'RandomForestClassifier': {'0': {'precision': 0.6035283194057567,\n",
       "   'recall': 0.9774436090225563,\n",
       "   'f1-score': 0.746268656716418,\n",
       "   'support': 665.0},\n",
       "  '1': {'precision': 0.7267950963222417,\n",
       "   'recall': 0.41624874623871616,\n",
       "   'f1-score': 0.5293367346938775,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.763014763014763,\n",
       "   'recall': 0.7714061272584446,\n",
       "   'f1-score': 0.7671875,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.6974446337308348,\n",
       "  'macro avg': {'precision': 0.6977793929142537,\n",
       "   'recall': 0.721699494173239,\n",
       "   'f1-score': 0.6809309638034318,\n",
       "   'support': 2935.0},\n",
       "  'weighted avg': {'precision': 0.7145754128640193,\n",
       "   'recall': 0.6974446337308348,\n",
       "   'f1-score': 0.6816514714501581,\n",
       "   'support': 2935.0}},\n",
       " 'RandomForestClassifier_eng': {'0': {'precision': 0.6292682926829268,\n",
       "   'recall': 0.9699248120300752,\n",
       "   'f1-score': 0.7633136094674556,\n",
       "   'support': 665.0},\n",
       "  '1': {'precision': 0.6863013698630137,\n",
       "   'recall': 0.5025075225677031,\n",
       "   'f1-score': 0.5801968731905037,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.7745762711864407,\n",
       "   'recall': 0.7179890023566379,\n",
       "   'f1-score': 0.7452099470036689,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.7018739352640545,\n",
       "  'macro avg': {'precision': 0.6967153112441271,\n",
       "   'recall': 0.7301404456514721,\n",
       "   'f1-score': 0.6962401432205428,\n",
       "   'support': 2935.0},\n",
       "  'weighted avg': {'precision': 0.7116666008885554,\n",
       "   'recall': 0.7018739352640545,\n",
       "   'f1-score': 0.6932579541405318,\n",
       "   'support': 2935.0}},\n",
       " 'GradientBoostingClassifier_eng': {'0': {'precision': 0.8204697986577181,\n",
       "   'recall': 0.7353383458646616,\n",
       "   'f1-score': 0.7755749405233942,\n",
       "   'support': 665.0},\n",
       "  '1': {'precision': 0.4107060452238117,\n",
       "   'recall': 0.892678034102307,\n",
       "   'f1-score': 0.5625790139064475,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 1.0,\n",
       "   'recall': 0.13511390416339356,\n",
       "   'f1-score': 0.23806228373702423,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.5284497444633731,\n",
       "  'macro avg': {'precision': 0.7437252812938433,\n",
       "   'recall': 0.5877100947101207,\n",
       "   'f1-score': 0.5254054127222886,\n",
       "   'support': 2935.0},\n",
       "  'weighted avg': {'precision': 0.7591435581586108,\n",
       "   'recall': 0.5284497444633731,\n",
       "   'f1-score': 0.4700858260681489,\n",
       "   'support': 2935.0}},\n",
       " 'BaggingClassifier_eng': {'0': {'precision': 0.8699551569506726,\n",
       "   'recall': 0.5834586466165413,\n",
       "   'f1-score': 0.6984698469846985,\n",
       "   'support': 665.0},\n",
       "  '1': {'precision': 0.38167006109979634,\n",
       "   'recall': 0.9398194583751254,\n",
       "   'f1-score': 0.5428736964078795,\n",
       "   'support': 997.0},\n",
       "  '2': {'precision': 0.9411764705882353,\n",
       "   'recall': 0.02513747054202671,\n",
       "   'f1-score': 0.04896710022953328,\n",
       "   'support': 1273.0},\n",
       "  'accuracy': 0.462350936967632,\n",
       "  'macro avg': {'precision': 0.7309338962129015,\n",
       "   'recall': 0.5161385251778978,\n",
       "   'f1-score': 0.43010354787403715,\n",
       "   'support': 2935.0},\n",
       "  'weighted avg': {'precision': 0.7349788338492395,\n",
       "   'recall': 0.462350936967632,\n",
       "   'f1-score': 0.36390549988268356,\n",
       "   'support': 2935.0}}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
